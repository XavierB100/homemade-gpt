{% extends "base.html" %}

{% block title %}About - HomeMade GPT Research Platform{% endblock %}

{% block extra_head %}
<style>
    .hero-section {
        background: radial-gradient(ellipse at center, rgba(99, 102, 241, 0.1) 0%, var(--bg-primary) 70%);
        padding: 60px 0;
        text-align: center;
        border-radius: 20px;
        margin-bottom: 40px;
        position: relative;
        overflow: hidden;
    }
    
    .hero-section::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        bottom: 0;
        background: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='60' height='60' viewBox='0 0 60 60'%3E%3Cg fill-rule='evenodd'%3E%3Cg fill='%236366f1' fill-opacity='0.05'%3E%3Ccircle cx='10' cy='10' r='2'/%3E%3C/g%3E%3C/g%3E%3C/svg%3E");
        animation: float 20s ease-in-out infinite;
    }
    
    @keyframes float {
        0%, 100% { transform: translateX(0px) translateY(0px); }
        50% { transform: translateX(30px) translateY(-30px); }
    }
    
    .hero-title {
        font-size: 3.5rem;
        font-weight: 700;
        background: linear-gradient(135deg, var(--text-primary), var(--purple-primary));
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        margin-bottom: 20px;
        position: relative;
        z-index: 2;
    }
    
    .hero-subtitle {
        font-size: 1.3rem;
        color: var(--text-secondary);
        margin-bottom: 30px;
        position: relative;
        z-index: 2;
    }
    
    .tech-badge {
        display: inline-block;
        background: rgba(99, 102, 241, 0.1);
        color: var(--purple-primary);
        padding: 8px 16px;
        border-radius: 20px;
        font-size: 14px;
        font-weight: 600;
        margin: 4px;
        border: 1px solid var(--purple-primary);
        transition: all 0.3s ease;
    }
    
    .tech-badge:hover {
        background: var(--purple-primary);
        color: white;
        transform: translateY(-2px);
    }
    
    .architecture-diagram {
        background: var(--bg-secondary);
        border: 2px solid var(--bg-tertiary);
        border-radius: 12px;
        padding: 30px;
        text-align: center;
        position: relative;
        overflow: hidden;
    }
    
    .layer-box {
        background: linear-gradient(135deg, rgba(99, 102, 241, 0.1), rgba(139, 92, 246, 0.1));
        border: 2px solid var(--purple-primary);
        border-radius: 8px;
        padding: 15px;
        margin: 10px 0;
        position: relative;
        transition: all 0.3s ease;
    }
    
    .layer-box:hover {
        transform: scale(1.02);
        box-shadow: 0 8px 25px rgba(99, 102, 241, 0.3);
    }
    
    .code-example {
        background: var(--bg-secondary);
        border: 1px solid var(--purple-primary);
        border-radius: 8px;
        padding: 20px;
        font-family: 'JetBrains Mono', monospace;
        font-size: 14px;
        line-height: 1.5;
        position: relative;
        margin: 20px 0;
        color: var(--text-primary);
    }
    
    .code-example::before {
        content: "Python";
        position: absolute;
        top: -10px;
        left: 20px;
        background: var(--purple-primary);
        color: white;
        padding: 4px 12px;
        border-radius: 12px;
        font-size: 12px;
        font-weight: 600;
    }
    
    .feature-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
        gap: 20px;
        margin: 30px 0;
    }
    
    .feature-card {
        background: var(--bg-secondary);
        border: 1px solid var(--bg-tertiary);
        border-radius: 12px;
        padding: 25px;
        text-align: center;
        transition: all 0.3s ease;
        position: relative;
        overflow: hidden;
    }
    
    .feature-card::before {
        content: '';
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 2px;
        background: var(--gradient-purple);
        transition: all 0.3s ease;
    }
    
    .feature-card:hover::before {
        left: 0;
    }
    
    .feature-card:hover {
        transform: translateY(-5px);
        border-color: var(--purple-primary);
    }
    
    .feature-icon {
        font-size: 2.5rem;
        color: var(--purple-primary);
        margin-bottom: 15px;
    }
    
    .stats-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 20px;
        margin: 30px 0;
    }
    
    .stat-card {
        background: var(--bg-secondary);
        border: 1px solid var(--bg-tertiary);
        border-radius: 12px;
        padding: 20px;
        text-align: center;
        transition: all 0.3s ease;
    }
    
    .stat-card:hover {
        border-color: var(--cyan-primary);
        transform: scale(1.05);
    }
    
    .stat-number {
        font-size: 2rem;
        font-weight: 700;
        color: var(--cyan-primary);
        font-family: 'JetBrains Mono', monospace;
    }
    
    .stat-label {
        color: var(--text-secondary);
        font-size: 14px;
        margin-top: 5px;
    }
    
    .workflow-step {
        display: flex;
        align-items: center;
        margin: 20px 0;
        padding: 20px;
        background: var(--bg-secondary);
        border-radius: 12px;
        border-left: 4px solid var(--purple-primary);
        transition: all 0.3s ease;
    }
    
    .workflow-step:hover {
        background: var(--bg-tertiary);
        transform: translateX(10px);
    }
    
    .step-number {
        background: var(--purple-primary);
        color: white;
        width: 40px;
        height: 40px;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        font-weight: bold;
        margin-right: 20px;
    }
    
    .interactive-demo {
        background: var(--bg-secondary);
        border: 2px solid var(--purple-primary);
        border-radius: 12px;
        padding: 30px;
        margin: 30px 0;
        text-align: center;
    }
    
    .demo-button {
        background: var(--gradient-purple);
        border: none;
        color: white;
        padding: 15px 30px;
        border-radius: 25px;
        font-weight: 600;
        font-size: 16px;
        cursor: pointer;
        transition: all 0.3s ease;
        margin: 10px;
    }
    
    .demo-button:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(99, 102, 241, 0.4);
    }
    
    .demo-output {
        background: var(--bg-primary);
        border: 1px solid var(--bg-tertiary);
        border-radius: 8px;
        padding: 20px;
        margin-top: 20px;
        font-family: 'JetBrains Mono', monospace;
        text-align: left;
        min-height: 100px;
        color: var(--green-primary);
    }
    
    @media (max-width: 768px) {
        .hero-title {
            font-size: 2.5rem;
        }
        
        .feature-grid, .stats-grid {
            grid-template-columns: 1fr;
        }
    }
</style>
{% endblock %}

{% block content %}
<!-- Hero Section -->
<div class="hero-section">
    <h1 class="hero-title">üß† HomeMade GPT</h1>
    <p class="hero-subtitle">Educational Transformer Language Model Training Platform</p>
    <div class="mb-4">
        <span class="tech-badge">PyTorch</span>
        <span class="tech-badge">Transformers</span>
        <span class="tech-badge">Flask</span>
        <span class="tech-badge">Character-Level</span>
        <span class="tech-badge">Real-time Training</span>
        <span class="tech-badge">WebSockets</span>
    </div>
</div>

<!-- Simple Explanation -->
<div class="row mb-5">
    <div class="col-12">
        <div class="card">
            <div class="card-header">
                <h3><i class="bi bi-chat-heart-fill"></i> In Simple Terms...</h3>
            </div>
            <div class="card-body">
                <div class="row align-items-center">
                    <div class="col-md-8">
                        <p style="font-size: 1.2rem; color: var(--text-primary); margin-bottom: 20px; line-height: 1.7;">
                            <strong>Think of this like teaching a computer to write like Shakespeare or chat like your friends.</strong> 
                            It's a neural network that learns patterns in text, just like how your brain learns to recognize writing styles.
                        </p>
                        
                        <div style="background: var(--bg-tertiary); border-radius: 8px; padding: 20px; margin-bottom: 20px; border-left: 4px solid var(--cyan-primary);">
                            <h6 style="color: var(--cyan-primary); margin-bottom: 15px;">The Machine Learning Process:</h6>
                            <div style="color: var(--text-secondary);">
                                <p><i class="bi bi-upload" style="color: var(--purple-primary); margin-right: 8px;"></i><strong>1. Feed it data</strong> - Upload text (books, chats, articles) that becomes the "training data"</p>
                                <p><i class="bi bi-gear-fill" style="color: var(--purple-primary); margin-right: 8px;"></i><strong>2. Train the neural network</strong> - The AI reads through your text thousands of times, learning which characters and words typically come after others</p>
                                <p><i class="bi bi-graph-up" style="color: var(--purple-primary); margin-right: 8px;"></i><strong>3. Optimize & improve</strong> - The model gets better by adjusting millions of "weights" (like synapses in a brain) to minimize prediction errors</p>
                                <p><i class="bi bi-chat-dots" style="color: var(--purple-primary); margin-right: 8px;"></i><strong>4. Generate new text</strong> - You give it a prompt, and it predicts the most likely next characters based on what it learned</p>
                                <p style="margin: 0;"><i class="bi bi-stars" style="color: var(--purple-primary); margin-right: 8px;"></i><strong>5. Get results</strong> - It creates new text that statistically resembles your training data's style and patterns</p>
                            </div>
                        </div>
                        
                        <div style="background: var(--bg-primary); border-radius: 8px; padding: 15px; margin-bottom: 20px; border: 1px solid var(--bg-tertiary);">
                            <p style="color: var(--text-secondary); font-size: 14px; margin: 0;">
                                <i class="bi bi-lightbulb" style="color: var(--cyan-primary); margin-right: 8px;"></i>
                                <strong>The key insight:</strong> Instead of programming rules for how to write, we let the computer discover the patterns by showing it lots of examples. 
                                It's like learning a language by reading lots of books rather than memorizing grammar rules.
                            </p>
                        </div>
                        
                        <p style="color: var(--text-secondary); font-style: italic;">
                            "It's like having a personal AI that learned to write by reading your favorite authors and mimicking their style!"
                        </p>
                    </div>
                    
                    <div class="col-md-4 text-center">
                        <div style="margin-bottom: 25px; padding: 20px; background: var(--bg-primary); border-radius: 8px; border: 1px solid var(--bg-tertiary);">
                            <h6 style="color: var(--text-primary); margin-bottom: 15px;">The Learning Process:</h6>
                            <div style="display: flex; justify-content: center; align-items: center; gap: 12px; margin-bottom: 15px;">
                                <div style="text-align: center;">
                                    <i class="bi bi-brain" style="font-size: 2.2rem; color: var(--purple-primary); display: block;"></i>
                                    <small style="color: var(--text-muted); font-size: 11px;">Human Brain</small>
                                </div>
                                <i class="bi bi-arrow-right" style="font-size: 1.2rem; color: var(--cyan-primary);"></i>
                                <div style="text-align: center;">
                                    <i class="bi bi-laptop" style="font-size: 2.2rem; color: var(--green-primary); display: block;"></i>
                                    <small style="color: var(--text-muted); font-size: 11px;">Neural Network</small>
                                </div>
                            </div>
                            <p style="font-size: 12px; color: var(--text-secondary); margin: 0;">
                                Pattern recognition transferred to artificial neurons
                            </p>
                        </div>
                        
                        <h6 style="color: var(--text-primary); margin-bottom: 15px;">Training Examples:</h6>
                        <div style="font-size: 14px; color: var(--text-secondary);">
                            <p><i class="bi bi-book" style="color: var(--purple-primary); margin-right: 5px;"></i><strong>Shakespeare:</strong><br>"Thou art most beauteous"</p>
                            <p><i class="bi bi-whatsapp" style="color: var(--green-primary); margin-right: 5px;"></i><strong>WhatsApp:</strong><br>"lol that's so funny üòÇ"</p>
                            <p><i class="bi bi-newspaper" style="color: var(--cyan-primary); margin-right: 5px;"></i><strong>News:</strong><br>"According to recent reports..."</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Project Overview -->
<div class="row mb-5">
    <div class="col-12">
        <div class="card">
            <div class="card-header">
                <h3><i class="bi bi-lightbulb-fill"></i> What Is This Project?</h3>
            </div>
            <div class="card-body">
                <p style="font-size: 1.1rem; color: var(--text-primary); margin-bottom: 25px;">
                    <strong>HomeMade GPT</strong> is an educational platform that demonstrates how modern AI language models work under the hood. 
                    Built from scratch using PyTorch, it implements a character-level transformer architecture similar to GPT, 
                    complete with a beautiful web interface for training, chatting, and model management.
                </p>
                
                <div class="row">
                    <div class="col-md-6">
                        <h5 style="color: var(--purple-primary);">üéØ Purpose</h5>
                        <ul style="color: var(--text-secondary);">
                            <li>Learn how transformers and attention mechanisms work</li>
                            <li>Understand neural language model training</li>
                            <li>Experience the full ML workflow from data to deployment</li>
                            <li>Experiment with different architectures and hyperparameters</li>
                        </ul>
                    </div>
                    <div class="col-md-6">
                        <h5 style="color: var(--cyan-primary);">‚ú® Key Features</h5>
                        <ul style="color: var(--text-secondary);">
                            <li>Train models on any text data (books, chats, documents)</li>
                            <li>Real-time training progress with WebSocket updates</li>
                            <li>Interactive chat interface with your trained models</li>
                            <li>Model management and performance analytics</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- System Statistics -->
<div class="stats-grid">
    <div class="stat-card">
        <div class="stat-number">{{ system_info.models_count }}</div>
        <div class="stat-label">Trained Models</div>
    </div>
    <div class="stat-card">
        <div class="stat-number">{{ "%.1f"|format(system_info.project_size) }}MB</div>
        <div class="stat-label">Project Size</div>
    </div>
    <div class="stat-card">
        <div class="stat-number">{{ system_info.python_version }}</div>
        <div class="stat-label">Python Version</div>
    </div>
    <div class="stat-card">
        <div class="stat-number">{% if system_info.cuda_available %}GPU{% else %}CPU{% endif %}</div>
        <div class="stat-label">Training Device</div>
    </div>
</div>

<!-- Architecture Deep Dive -->
<div class="row mb-5">
    <div class="col-12">
        <div class="card">
            <div class="card-header">
                <h3><i class="bi bi-diagram-3-fill"></i> Neural Network Architecture</h3>
            </div>
            <div class="card-body">
                <p style="color: var(--text-secondary); margin-bottom: 30px;">
                    Our implementation follows the transformer architecture from "Attention Is All You Need" (Vaswani et al., 2017) with modern improvements:
                </p>
                
                <div class="architecture-diagram">
                    <h5 style="color: var(--purple-primary); margin-bottom: 25px;">üèóÔ∏è Layer Stack</h5>
                    
                    <div class="layer-box">
                        <strong style="color: var(--text-primary);">Language Model Head</strong>
                        <br><small style="color: var(--text-muted);">Linear(n_embd ‚Üí vocab_size) ‚Ä¢ Converts embeddings to token probabilities</small>
                    </div>
                    
                    <div class="layer-box">
                        <strong style="color: var(--text-primary);">Layer Normalization</strong>
                        <br><small style="color: var(--text-muted);">Final normalization before output</small>
                    </div>
                    
                    <div class="layer-box">
                        <strong style="color: var(--text-primary);">N √ó Transformer Blocks</strong>
                        <br><small style="color: var(--text-muted);">Multi-head Attention + Feed-forward Network + Residual Connections</small>
                    </div>
                    
                    <div class="layer-box">
                        <strong style="color: var(--text-primary);">Dropout Layer</strong>
                        <br><small style="color: var(--text-muted);">Regularization to prevent overfitting</small>
                    </div>
                    
                    <div class="layer-box">
                        <strong style="color: var(--text-primary);">Positional Embeddings</strong>
                        <br><small style="color: var(--text-muted);">Learned position encoding (0 to block_size)</small>
                    </div>
                    
                    <div class="layer-box">
                        <strong style="color: var(--text-primary);">Token Embeddings</strong>
                        <br><small style="color: var(--text-muted);">Character-level embedding lookup table</small>
                    </div>
                </div>
                
                <div class="code-example">
<pre style="margin: 0; color: var(--text-primary); background: transparent;"># Core transformer block implementation
class Block(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)
        self.attn = CausalSelfAttention(config)  # Multi-head attention
        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)
        self.mlp = MLP(config)  # Feed-forward network
        
    def forward(self, x):
        # Pre-normalization (more stable than post-norm)
        x = x + self.attn(self.ln_1(x))  # Attention + residual
        x = x + self.mlp(self.ln_2(x))   # MLP + residual
        return x</pre>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Key Components -->
<div class="row mb-5">
    <div class="col-12">
        <h2 class="text-center mb-4" style="color: var(--text-primary);">üîß System Components</h2>
    </div>
</div>

<div class="feature-grid">
    <div class="feature-card">
        <i class="bi bi-brain feature-icon"></i>
        <h4 style="color: var(--text-primary);">Enhanced GPT Model</h4>
        <p style="color: var(--text-secondary);">
            Modern transformer implementation with multi-head attention, pre-normalization, 
            GELU activation, and configurable architecture (nano to large sizes).
        </p>
        <div style="margin-top: 15px;">
            <code style="font-size: 12px;">src/models/enhanced_gpt.py</code>
        </div>
    </div>
    
    <div class="feature-card">
        <i class="bi bi-database-fill feature-icon"></i>
        <h4 style="color: var(--text-primary);">Smart Data Processing</h4>
        <p style="color: var(--text-secondary);">
            Automatic format detection for plain text and WhatsApp conversations, 
            with intelligent preprocessing and character-level tokenization.
        </p>
        <div style="margin-top: 15px;">
            <code style="font-size: 12px;">src/training/data_loader.py</code>
        </div>
    </div>
    
    <div class="feature-card">
        <i class="bi bi-lightning-fill feature-icon"></i>
        <h4 style="color: var(--text-primary);">Real-time Training</h4>
        <p style="color: var(--text-secondary);">
            WebSocket-powered live training updates, progress tracking, loss monitoring, 
            and automatic model checkpointing during training.
        </p>
        <div style="margin-top: 15px;">
            <code style="font-size: 12px;">src/training/train.py</code>
        </div>
    </div>
    
    <div class="feature-card">
        <i class="bi bi-chat-dots-fill feature-icon"></i>
        <h4 style="color: var(--text-primary);">Interactive Chat</h4>
        <p style="color: var(--text-secondary);">
            Advanced text generation with temperature control, top-k and nucleus sampling, 
            plus backward compatibility for loading older models.
        </p>
        <div style="margin-top: 15px;">
            <code style="font-size: 12px;">src/chat/chat.py</code>
        </div>
    </div>
    
    <div class="feature-card">
        <i class="bi bi-globe feature-icon"></i>
        <h4 style="color: var(--text-primary);">Modern Web Interface</h4>
        <p style="color: var(--text-secondary);">
            Flask-based web application with dark theme, responsive design, 
            real-time updates, and professional UI components.
        </p>
        <div style="margin-top: 15px;">
            <code style="font-size: 12px;">web_app.py + templates/</code>
        </div>
    </div>
    
    <div class="feature-card">
        <i class="bi bi-folder-fill feature-icon"></i>
        <h4 style="color: var(--text-primary);">Clean Architecture</h4>
        <p style="color: var(--text-secondary);">
            Organized project structure with proper imports, backward compatibility, 
            and modular design for easy extension and maintenance.
        </p>
        <div style="margin-top: 15px;">
            <code style="font-size: 12px;">src/ structure</code>
        </div>
    </div>
</div>

<!-- How It Works -->
<div class="row mb-5">
    <div class="col-12">
        <div class="card">
            <div class="card-header">
                <h3><i class="bi bi-gear-fill"></i> How The Training Process Works</h3>
            </div>
            <div class="card-body">
                <div class="workflow-step">
                    <div class="step-number">1</div>
                    <div>
                        <h6 style="color: var(--text-primary);">Data Upload & Processing</h6>
                        <p style="color: var(--text-secondary); margin: 0;">
                            Upload text files ‚Üí Auto-detect format (plain text/WhatsApp) ‚Üí Clean and preprocess ‚Üí 
                            Build character-level vocabulary ‚Üí Split into train/validation sets
                        </p>
                    </div>
                </div>
                
                <div class="workflow-step">
                    <div class="step-number">2</div>
                    <div>
                        <h6 style="color: var(--text-primary);">Model Configuration</h6>
                        <p style="color: var(--text-secondary); margin: 0;">
                            Choose model size (nano to large) ‚Üí Set hyperparameters ‚Üí Initialize transformer architecture ‚Üí 
                            Configure AdamW optimizer with weight decay
                        </p>
                    </div>
                </div>
                
                <div class="workflow-step">
                    <div class="step-number">3</div>
                    <div>
                        <h6 style="color: var(--text-primary);">Training Loop</h6>
                        <p style="color: var(--text-secondary); margin: 0;">
                            Forward pass ‚Üí Calculate loss ‚Üí Backward pass ‚Üí Gradient clipping ‚Üí 
                            Update weights ‚Üí Learning rate scheduling ‚Üí Periodic evaluation ‚Üí Save best models
                        </p>
                    </div>
                </div>
                
                <div class="workflow-step">
                    <div class="step-number">4</div>
                    <div>
                        <h6 style="color: var(--text-primary);">Real-time Monitoring</h6>
                        <p style="color: var(--text-secondary); margin: 0;">
                            WebSocket updates ‚Üí Live progress tracking ‚Üí Loss visualization ‚Üí 
                            Training logs ‚Üí Automatic completion notification
                        </p>
                    </div>
                </div>
                
                <div class="workflow-step">
                    <div class="step-number">5</div>
                    <div>
                        <h6 style="color: var(--text-primary);">Model Usage</h6>
                        <p style="color: var(--text-secondary); margin: 0;">
                            Load trained model ‚Üí Interactive chat interface ‚Üí Adjust generation parameters ‚Üí 
                            Generate text with temperature/top-k/nucleus sampling
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Interactive Demo -->
<div class="interactive-demo">
    <h3 style="color: var(--purple-primary); margin-bottom: 20px;">üéÆ Interactive Architecture Explorer</h3>
    <p style="color: var(--text-secondary); margin-bottom: 25px;">
        Click the buttons below to explore different aspects of the transformer architecture:
    </p>
    
    <div>
        <button class="demo-button" onclick="showArchitectureInfo('attention')">
            üîç Multi-Head Attention
        </button>
        <button class="demo-button" onclick="showArchitectureInfo('feedforward')">
            üîß Feed-Forward Network
        </button>
        <button class="demo-button" onclick="showArchitectureInfo('embeddings')">
            üìä Embeddings
        </button>
        <button class="demo-button" onclick="showArchitectureInfo('training')">
            üöÄ Training Process
        </button>
    </div>
    
    <div class="demo-output" id="architectureOutput">
        <div style="color: var(--text-muted); text-align: center; padding: 20px;">
            üëÜ Click a button above to explore the architecture components
        </div>
    </div>
</div>

<!-- Technical Specifications -->
<div class="row mb-5">
    <div class="col-md-6">
        <div class="card">
            <div class="card-header">
                <h5><i class="bi bi-cpu-fill"></i> Model Specifications</h5>
            </div>
            <div class="card-body">
                <div class="row mb-3">
                    <div class="col-6" style="color: var(--text-primary);"><strong>Nano Model:</strong></div>
                    <div class="col-6" style="color: var(--cyan-primary);">0.8M parameters</div>
                </div>
                <div class="row mb-3">
                    <div class="col-6" style="color: var(--text-primary);"><strong>Tiny Model:</strong></div>
                    <div class="col-6" style="color: var(--cyan-primary);">10M parameters</div>
                </div>
                <div class="row mb-3">
                    <div class="col-6" style="color: var(--text-primary);"><strong>Large Model:</strong></div>
                    <div class="col-6" style="color: var(--cyan-primary);">150M parameters</div>
                </div>
                <div class="row mb-3">
                    <div class="col-6" style="color: var(--text-primary);"><strong>Context Length:</strong></div>
                    <div class="col-6" style="color: var(--green-primary);">128-512 tokens</div>
                </div>
                <div class="row mb-3">
                    <div class="col-6" style="color: var(--text-primary);"><strong>Vocabulary:</strong></div>
                    <div class="col-6" style="color: var(--green-primary);">Character-level</div>
                </div>
                <div class="row">
                    <div class="col-6" style="color: var(--text-primary);"><strong>Attention Heads:</strong></div>
                    <div class="col-6" style="color: var(--purple-primary);">3-16 heads</div>
                </div>
            </div>
        </div>
    </div>
    
    <div class="col-md-6">
        <div class="card">
            <div class="card-header">
                <h5><i class="bi bi-tools"></i> Technical Stack</h5>
            </div>
            <div class="card-body">
                <div class="row mb-3">
                    <div class="col-6" style="color: var(--text-primary);"><strong>Deep Learning:</strong></div>
                    <div class="col-6" style="color: var(--cyan-primary);">PyTorch {{ system_info.pytorch_version }}</div>
                </div>
                <div class="row mb-3">
                    <div class="col-6" style="color: var(--text-primary);"><strong>Web Framework:</strong></div>
                    <div class="col-6" style="color: var(--cyan-primary);">Flask + SocketIO</div>
                </div>
                <div class="row mb-3">
                    <div class="col-6" style="color: var(--text-primary);"><strong>Frontend:</strong></div>
                    <div class="col-6" style="color: var(--green-primary);">Bootstrap 5 + JS</div>
                </div>
                <div class="row mb-3">
                    <div class="col-6" style="color: var(--text-primary);"><strong>Optimizer:</strong></div>
                    <div class="col-6" style="color: var(--green-primary);">AdamW + Scheduling</div>
                </div>
                <div class="row mb-3">
                    <div class="col-6" style="color: var(--text-primary);"><strong>Activation:</strong></div>
                    <div class="col-6" style="color: var(--purple-primary);">GELU</div>
                </div>
                <div class="row">
                    <div class="col-6" style="color: var(--text-primary);"><strong>Normalization:</strong></div>
                    <div class="col-6" style="color: var(--purple-primary);">LayerNorm</div>
                </div>
            </div>
        </div>
    </div>
</div>

{% endblock %}

{% block extra_scripts %}
<script>
function showArchitectureInfo(component) {
    const output = document.getElementById('architectureOutput');
    
    const info = {
        attention: `
<div style="color: var(--green-primary); font-weight: bold; margin-bottom: 10px;">üîç Multi-Head Attention Mechanism</div>
<div style="color: var(--text-primary);">
‚Ä¢ <strong>Purpose:</strong> Allows model to focus on different parts of input sequence simultaneously<br>
‚Ä¢ <strong>Query, Key, Value:</strong> Three learned linear projections of input<br>
‚Ä¢ <strong>Scaled Dot-Product:</strong> Attention(Q,K,V) = softmax(QK^T/‚àöd_k)V<br>
‚Ä¢ <strong>Multi-Head:</strong> Run attention multiple times in parallel with different learned projections<br>
‚Ä¢ <strong>Causal Masking:</strong> Prevents model from looking at future tokens during training<br><br>

<strong style="color: var(--purple-primary);">Code Implementation:</strong><br>
<span style="color: var(--cyan-primary);">att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))</span><br>
<span style="color: var(--cyan-primary);">att = F.softmax(att, dim=-1)</span><br>
<span style="color: var(--cyan-primary);">y = att @ v  # Weighted combination of values</span>
</div>`,
        
        feedforward: `
<div style="color: var(--green-primary); font-weight: bold; margin-bottom: 10px;">üîß Feed-Forward Network (MLP)</div>
<div style="color: var(--text-primary);">
‚Ä¢ <strong>Architecture:</strong> Linear ‚Üí GELU ‚Üí Linear ‚Üí Dropout<br>
‚Ä¢ <strong>Expansion:</strong> Hidden size is 4x the embedding dimension<br>
‚Ä¢ <strong>GELU Activation:</strong> More natural than ReLU: x * Œ¶(x)<br>
‚Ä¢ <strong>Purpose:</strong> Non-linear transformation after attention<br>
‚Ä¢ <strong>Residual Connection:</strong> x = x + MLP(LayerNorm(x))<br><br>

<strong style="color: var(--purple-primary);">Code Implementation:</strong><br>
<span style="color: var(--cyan-primary);">x = self.c_fc(x)    # Linear: embd ‚Üí 4*embd</span><br>
<span style="color: var(--cyan-primary);">x = self.gelu(x)    # GELU activation</span><br>
<span style="color: var(--cyan-primary);">x = self.c_proj(x)  # Linear: 4*embd ‚Üí embd</span><br>
<span style="color: var(--cyan-primary);">x = self.dropout(x) # Regularization</span>
</div>`,
        
        embeddings: `
<div style="color: var(--green-primary); font-weight: bold; margin-bottom: 10px;">üìä Token & Positional Embeddings</div>
<div style="color: var(--text-primary);">
‚Ä¢ <strong>Token Embeddings:</strong> Convert character indices to dense vectors<br>
‚Ä¢ <strong>Positional Embeddings:</strong> Add position information to tokens<br>
‚Ä¢ <strong>Character-Level:</strong> Each character gets its own embedding<br>
‚Ä¢ <strong>Learned Positions:</strong> Positions 0 to block_size each have learned embeddings<br>
‚Ä¢ <strong>Addition:</strong> tok_emb + pos_emb = final input to transformer<br><br>

<strong style="color: var(--purple-primary);">Code Implementation:</strong><br>
<span style="color: var(--cyan-primary);">tok_emb = self.wte(idx)  # Token embeddings</span><br>
<span style="color: var(--cyan-primary);">pos_emb = self.wpe(pos)  # Position embeddings</span><br>
<span style="color: var(--cyan-primary);">x = tok_emb + pos_emb    # Combine both</span><br>
<span style="color: var(--cyan-primary);">x = self.drop(x)         # Apply dropout</span>
</div>`,
        
        training: `
<div style="color: var(--green-primary); font-weight: bold; margin-bottom: 10px;">üöÄ Training Process</div>
<div style="color: var(--text-primary);">
‚Ä¢ <strong>Data Processing:</strong> Character-level tokenization ‚Üí batching<br>
‚Ä¢ <strong>Forward Pass:</strong> Input through transformer ‚Üí calculate loss<br>
‚Ä¢ <strong>Backward Pass:</strong> Gradients via backpropagation<br>
‚Ä¢ <strong>Optimization:</strong> AdamW with weight decay and learning rate scheduling<br>
‚Ä¢ <strong>Evaluation:</strong> Regular validation loss computation<br>
‚Ä¢ <strong>Checkpointing:</strong> Save best models automatically<br><br>

<strong style="color: var(--purple-primary);">Training Loop:</strong><br>
<span style="color: var(--cyan-primary);">logits, loss = model(X, Y)  # Forward pass</span><br>
<span style="color: var(--cyan-primary);">loss.backward()             # Compute gradients</span><br>
<span style="color: var(--cyan-primary);">optimizer.step()            # Update weights</span><br>
<span style="color: var(--cyan-primary);">scheduler.step()            # Update learning rate</span>
</div>`
    };
    
    output.innerHTML = info[component] || '<div style="color: var(--text-muted);">Component information not found.</div>';
    
    // Add animation
    output.style.opacity = '0';
    setTimeout(() => {
        output.style.opacity = '1';
        output.style.transition = 'opacity 0.3s ease';
    }, 100);
}

// Auto-show attention info on load
document.addEventListener('DOMContentLoaded', function() {
    setTimeout(() => {
        showArchitectureInfo('attention');
    }, 1000);
});
</script>
{% endblock %}
